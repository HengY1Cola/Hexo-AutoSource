---
title: Pythonæµ…è°ˆå¤šçº¿ç¨‹
categories: å¼€å‘
keywords: å¤šçº¿ç¨‹
top_img: /img/104512.webp
cover: /img/3656799.webp
abbrlink: 6e07425f
date: 2022-02-22 23:46:21
---

##  å‰è¨€ï¼š

åªè¦ç©è¿‡**çˆ¬è™«**çš„ï¼Œå°±çŸ¥é“çº¿ç¨‹çš„å¿…è¦æ€§ã€‚ä½†æ˜¯æˆ‘å­¦ä¹ çº¿ç¨‹çš„è·¯å­æ¯”è¾ƒé‡ï½

æ‰€ä»¥å­¦çš„ä¸æ˜¯é‚£ä¹ˆ**ç³»ç»Ÿ**ï¼Œæœ€è¿‘æ²¡äº‹æ¥çœ‹çœ‹æŠŠé‡è¦çš„éƒ¨åˆ†éƒ½æ¥æŒæ¡ä¸‹ã€‚

ç„¶åä¹Ÿå°±â€œ**ç®€ç®€å•å•**â€æ°´ä¸€ç¯‡é‡ç‚¹éƒ¨åˆ†ï¼ˆä¸»è¦æˆ‘æ€•åé¢å¿˜è®°äº†QAQï¼‰

##  å¼•å…¥ï¼š

`ä»€ä¹ˆæ˜¯GIL?`  åœ¨å®ç°Pythonè§£æå™¨(CPython)æ—¶æ‰€å¼•å…¥çš„ä¸€ä¸ªæ¦‚å¿µï¼ŒGILè¿™æŠŠè¶…çº§å¤§é”ï¼Œæ˜¯åŠ åœ¨å…¨å±€ä¸Šçš„

åŒä¸€ä¸ªæ—¶åˆ»åªæœ‰ä¸€ä¸ªçº¿ç¨‹åœ¨ä¸€ä¸ªcpuä¸Šæ‰§è¡Œå­—èŠ‚ç , æ— æ³•å°†å¤šä¸ªçº¿ç¨‹æ˜ å°„åˆ°å¤šä¸ªcpuä¸Šæ‰§è¡Œ

ä½†æ˜¯GILä¼šä¸»åŠ¨é‡Šæ”¾ï¼š1. æ ¹æ®æ‰§è¡Œçš„å­—èŠ‚ç è¡Œæ•°ä»¥åŠæ—¶é—´ç‰‡é‡Šæ”¾ï¼›2. åœ¨é‡åˆ°ioçš„æ“ä½œæ—¶å€™ä¸»åŠ¨é‡Šæ”¾

> *In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPythonâ€™s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)*

çœ‹ä¸ªä¾‹å­ï¼šè¿™ä¸ªæ€ä¹ˆéƒ½ä¸ä¼šå®ç°ä¸º0ã€‚å…·ä½“å¦‚ä½•è§£å†³çœ‹åé¢

```python
import threading

total = 0
def add():
    global total
    for i in range(1000000):
        total += 1
def desc():
    global total
    for i in range(1000000):
        total -= 1

thread1 = threading.Thread(target=add)
thread2 = threading.Thread(target=desc)
thread1.start()
thread2.start()
print(total)
```

## Threadçš„åŸºç¡€

è¿™é‡Œé¢çš„å‡ ä¸ªç‚¹ï¼š

1. é™¤äº†æœ€åŸºç¡€çš„å†™æ³•ï¼Œè¿˜å¯ä»¥ç»§æ‰¿`threading.Thread`é‡æ„æ–¹æ³•ï¼šä¾‹å¦‚Runæ–¹æ³•ï¼Œå°†é€»è¾‘å†™åœ¨é‡Œé¢
2. ä½¿ç”¨å¤šçº¿ç¨‹çš„åŸºæœ¬APIçš„æŒæ¡ï¼Œè¿™é‡Œå°±ä¸è´´æ¯ä¸ªAPIä»€ä¹ˆæ„æ€ã€‚ç¿»ç¿»æ–‡æ¡£å°±å¥½å•¦

```python
import time
import threading

class GetDetailHtml(threading.Thread):
    def __init__(self, name):
        super().__init__(name=name)

    def run(self):
        print("get detail html started")
        time.sleep(2)
        print("get detail html end")

class GetDetailUrl(threading.Thread):
    def __init__(self, name):
        super().__init__(name=name)

    def run(self):
        print("get detail url started")
        time.sleep(4)
        print("get detail url end")

if __name__ == "__main__":
    thread1 = GetDetailHtml("get_detail_html")
    thread2 = GetDetailUrl("get_detail_url")
    start_time = time.time()
    thread1.start()
    thread2.start()
    thread1.join()
    thread2.join()
    # å½“ä¸»çº¿ç¨‹é€€å‡ºçš„æ—¶å€™ï¼Œ å­çº¿ç¨‹killæ‰
    print("last time: {}".format(time.time() - start_time))
```

## å¤šä¸ªçº¿ç¨‹ä¹‹é—´çš„å˜é‡

> ä¼šäº§ç”Ÿéœ€æ±‚å°±æ˜¯ï¼Œå¤§å®¶åŒæ—¶æ“ä½œä¸€ä¸ªå˜é‡ã€‚è¿™ä¸ªå˜é‡å¯ä»¥ç©¿æ¢­åœ¨å„ä¸ªçº¿ç¨‹ä¹‹é—´

å½“ç„¶è¿™é‡Œæœ‰ä¸ªå¾ˆå¤§çš„BUGï¼Œæˆ‘å½“æ—¶å°±å¾ˆç–‘æƒ‘ğŸ¤”.

å°±æ˜¯åŠ å…¥ç°åœ¨æœ‰2ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯`utils.py`æ–‡ä»¶ä¸­çš„ä¸€ä¸ªå˜é‡test

å¦‚æœä½ æ˜¯ `import utils`ç„¶åä½¿ç”¨çš„æ˜¯`utils.test`è¿™ä¸ªçš„è¯æ˜¯å¯ä»¥çš„

ä½†æ˜¯ä½ æ˜¯`from utils import test`ä½¿ç”¨`test`çš„è¯ï¼Œä¸ç®¡ä½ æ€ä¹ˆæ”¹å˜ï¼Œä»–å°±ç®—ä¸€ä¸ªå®šå€¼äº†

æˆ‘å½“æ—¶å°±å¾ˆç–‘æƒ‘ä¸ºä»€ä¹ˆ`flag`å˜é‡æ— æ³•æ˜¯`while`é€€å‡ºï¼Œç°åœ¨çŸ¥é“é¿å‘äº†ã€‚

è¯´äº†è¿™ä¹ˆå¤šï¼Œå…¶å®å°±æ˜¯2ä¸ªæ–¹å¼

1. ä½¿ç”¨`gloablå…¨å±€å˜é‡`
2. ä½¿ç”¨`queue`ï¼ˆæ¨èï¼‰,å…·ä½“çš„APIç¿»ç¿»æ–‡æ¡£/æºç éƒ½è¡Œï¼Œä¸å¤šèµ˜è¿°

## èŠ±é‡Œèƒ¡å“¨çš„é”

###  Lockã€RLock

> ä½¿ç”¨é”å°±å¾ˆå¥½è§£å†³äº†ä¸Šé¢çš„é—®é¢˜ï¼Œå°±å¯ä»¥å¾—åˆ°ç­”æ¡ˆä¸º0

`Lock`ä¸`RLock`çš„å”¯ä¸€åŒºåˆ«å°±æ˜¯æœ‰æ•ˆå‡å°‘æ­»é”çš„å‘ç”Ÿ

ä»–ä»¬éƒ½æœ‰å…±åŒçš„`.acquire()`ä¸`.release()`è¿™ä¸ªä¸¤ä¸ªæ–¹å¼

ä½†æ˜¯`lock.acquire()`åœ¨ä¸ç»æ„ä¹‹é—´ä½¿ç”¨äº†2æ¬¡ï¼Œåˆ™ä¼šäº’ç›¸ç­‰å¾…å‘ç”Ÿæ­»é”ï¼Œéƒ½ä¸ä¼šåŠ¨äº†

è€Œ`RLock.acquire()`å¯ä»¥ä½¿ç”¨å¤šæ¬¡å¹¶ä¸”å¤šæ¬¡é‡Šæ”¾ï¼Œå‡å°‘æ­»é”ç«äº‰çš„æƒ…å†µã€‚

###  condition ä½¿ç”¨

> è¿™ä¸ªä½¿ç”¨çš„æƒ…å†µæ˜¯ï¼šå‡è®¾ç°åœ¨æœ‰2ä¸ªçº¿ç¨‹ï¼Œçº¿ç¨‹aæ‰§è¡Œå®Œæ¯•ä¹‹åå‘¢çº¿ç¨‹bå†æ‰§è¡Œï¼Œçº¿ç¨‹bæ‰§è¡Œå®Œæ¯•ä¹‹åå‘¢å†æ‰§è¡Œçº¿ç¨‹a
>
> äº’ç›¸é€šçŸ¥å¯¹æ–¹ï¼Œå¤šçº¿æ‰§è¡Œï¼Œä½†å¯ä»¥å®ç°äº¤æ›¿

ç‰¹åˆ«æ³¨æ„ï¼š å¯åŠ¨çš„é¡ºåºå¾ˆé‡è¦â€¼ï¸

æŒæ¡2ä¸ªAPIï¼š `.notify()`ä¸`.wait()`é¡¾åæ€ä¹‰ï¼šä¸€ä¸ªé€šçŸ¥ä¸€ä¸ªç­‰å¾…

`é€šçŸ¥`å°±æ˜¯é€šçŸ¥ç­‰å¾…çš„å¯¹æ–¹ä½ å¯ä»¥å¼€å§‹æ‰§è¡Œäº†ï¼Œ`ç­‰å¾…`å°±æ˜¯ç­‰å¾…å¯¹æ–¹æ¥é€šçŸ¥æˆ‘

###  Semaphore ä½¿ç”¨

> è¿™ä¸ªä½¿ç”¨çš„æƒ…å†µå°±æ˜¯ï¼šforå¾ªç¯çš„è¯ä¸€ä¸‹å­å¯åŠ¨20ä¸ªå¾ªç¯ï¼Œè®¾å¤‡é¡¶ä¸ä½ã€‚
>
> ä½¿ç”¨Semaphoreå°±å¯ä»¥å†³å®šä¸€æ¬¡æ€§å¼€å¯å¤šå°‘ä¸ª

è¯¾ä¸Šè¿™ä¸ªä¾‹å­æ¯”è¾ƒç»å…¸ï¼š

æ³¨æ„`.release()`ä¸`sem.acquire()`çš„ä½ç½®

```python
import threading
import time

class HtmlSpider(threading.Thread):
    def __init__(self, url, sem):
        super().__init__()
        self.url = url
        self.sem = sem

    def run(self):
        time.sleep(2)
        print("got html text success")
        self.sem.release()

class UrlProducer(threading.Thread):
    def __init__(self, sem):
        super().__init__()
        self.sem = sem

    def run(self):
        for i in range(20):
            self.sem.acquire()
            html_thread = HtmlSpider("https://baidu.com/{}".format(i), self.sem)
            html_thread.start()

if __name__ == "__main__":
    sem = threading.Semaphore(3)
    url_producer = UrlProducer(sem)
    url_producer.start()
```

## çº¿ç¨‹æ± çš„ä½¿ç”¨

> çº¿ç¨‹æ± ç›¸æ¯”è¾ƒäºå¤šçº¿ç¨‹ï¼Œæ›´åŠ å…·æœ‰æ™ºèƒ½åŒ–ï¼Œè¯´ç™½äº†å°±æ˜¯æ›´åŠ çœå¿ƒ

ä¸ºä»€ä¹ˆè¦çº¿ç¨‹æ±  ? 

1. ä¸»çº¿ç¨‹ä¸­å¯ä»¥è·å–æŸä¸€ä¸ªçº¿ç¨‹çš„çŠ¶æ€æˆ–è€…æŸä¸€ä¸ªä»»åŠ¡çš„çŠ¶æ€ï¼Œä»¥åŠè¿”å›å€¼
2. å½“ä¸€ä¸ªçº¿ç¨‹å®Œæˆçš„æ—¶å€™æˆ‘ä»¬ä¸»çº¿ç¨‹èƒ½ç«‹å³çŸ¥é“
3. `from concurrent.futures import Future`çš„futureså’Œå¤šè¿›ç¨‹ç¼–ç æ¥å£ä¸€è‡´

æœ€å¥½è‡ªå·±æ”¹ä¸€ä¸‹ä½¿ç”¨withä¸Šä¸‹æ–‡`with ThreadPoolExecutor(3) as executor:`ï¼š

```python
# ä¸€ä¸ªä¸ªæäº¤
import time
from concurrent.futures import ThreadPoolExecutor

def get_html(times):
    print("start sleep {}".format(times))
    time.sleep(times)
    print("get page {} success".format(times))
    return times

executor = ThreadPoolExecutor(max_workers=1)
task = executor.submit(get_html, 3)  # submit æ˜¯ç«‹å³è¿”å›
task2 = executor.submit(get_html, 2)  # submit æ˜¯ç«‹å³è¿”å›
print(task.done())  # æ‰§è¡Œå®Œæˆæ²¡
print(task2.cancel())  # å› ä¸ºæ€»çš„çº¿ç¨‹ä¸º1 task2æ²¡æœ‰æ‰§è¡Œ æ‰€ä»¥å¯ä»¥å–æ¶ˆ
time.sleep(4)
print(task.done())
print(task.result())

# æ‰¹é‡æäº¤
import time
from concurrent.futures import ThreadPoolExecutor, as_completed, wait
def get_html(times):
    print("start sleep {}".format(times))
    time.sleep(times)
    print("get page {} success".format(times))
    return times

oneList = [2, 4, 3]
executor = ThreadPoolExecutor(max_workers=2)
# allTask = [executor.submit(get_html, each) for each in oneList]
# wait(allTask)  # æ‰€æœ‰çº¿ç¨‹æ‰§è¡Œå®Œæ¯•å†èµ°
# # ä¸€æ—¦æœ‰å®Œæˆçš„äº†å°±èƒ½è·å–åˆ°(è°å…ˆå®Œæˆ)
# for future in as_completed(allTask):  # è·å–åˆ°å·²ç»å®Œæˆçš„äº†
#     data = future.result()
#     print("! get {}".format(str(data)))
# æ¢ä¸ªå†™æ³• (ä½†æ˜¯ä¼šæŒ‰ç…§oneListçš„é¡ºåºï¼‰
for data in executor.map(get_html, oneList):
    print("! get {}".format(str(data)))
```

## å¤šè¿›ç¨‹ç¼–ç¨‹

> - è€—cpuçš„æ“ä½œï¼Œç”¨å¤šè¿›ç¨‹ç¼–ç¨‹ï¼Œ 
>
> - å¯¹äºioæ“ä½œæ¥è¯´ï¼Œ ä½¿ç”¨å¤šçº¿ç¨‹ç¼–ç¨‹
> - è¿›ç¨‹åˆ‡æ¢ä»£ä»·è¦é«˜äºçº¿ç¨‹

ä¸€èˆ¬éƒ½æ˜¯ç”¨å¤šçº¿ç¨‹ï¼Œå¤šè¿›ç¨‹ä¸å¤šçº¿ç¨‹çš„åº“ä½¿ç”¨å·®ä¸å¤šï½

```python
import time
from concurrent.futures import ProcessPoolExecutor, as_completed

def random_sleep(n):
    time.sleep(n)
    return n

if __name__ == "__main__":
    with ProcessPoolExecutor(3) as executor:
        all_task = [executor.submit(random_sleep, (num)) for num in [2] * 30]
        start_time = time.time()
        for future in as_completed(all_task):
            data = future.result()
            print("exe result: {}".format(data))
        print("last time is: {}".format(time.time() - start_time))
```

----

1. å…±äº«å…¨å±€å˜é‡åœ¨å¤šè¿›ç¨‹ä¸­æ˜¯ä¸ä½¿ç”¨çš„
2. multiprocessingä¸­çš„queueä¸èƒ½ç”¨äºpoolè¿›ç¨‹æ± 
3. poolä¸­çš„è¿›ç¨‹é—´é€šä¿¡éœ€è¦ä½¿ç”¨managerä¸­çš„queue
4. ä½¿ç”¨Pipeé€šä¿¡ï¼Œä½†æ˜¯åªèƒ½é€‚ç”¨äº2ä¸ªè¿›ç¨‹

```python
from queue import Queue # å¤šè¿›ç¨‹ä¸èƒ½ç”¨

from multiprocessing import Queue # æ­£å¸¸çš„å¤šè¿›ç¨‹ä½¿ç”¨

from multiprocessing import Manager # poolé‡Œé¢ä½¿ç”¨
Manager().Queue() 

from multiprocessing import Pipe
```



